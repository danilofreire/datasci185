---
title: "Lectures"
---

Please find below the schedule of our lectures. Each lecture includes a brief description and required readings. The lecture slides and additional resources will be posted on the course website and GitHub repository. Please remember that the schedule may change during the course. If you have any questions or need further assistance, please let me know!

## Module 0 — Orientation

### Lecture 1 — Course introduction; what AI means today  
Syllabus, assessment, expectations. A factual tour of AI in products and media and the questions we will address.

Readings:

- Stanford University's Human-Centered Artificial Intelligence (2025). [AI Index Annual Report](https://hai.stanford.edu/ai-index/2025-ai-index-report). An excellent report on the state of AI, with many useful charts and references.
- Our World in Data (2025). [Artificial intelligence](https://ourworldindata.org/artificial-intelligence). A concise overview of AI trends and applications, with links to further resources.
- Menlo Ventures (2025). [2025: the state of consumer AI](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/). How AI is being used in consumer products, with examples and market data.
- Morgan Stanley (2025). [AI's next leap: 5 trends shaping innovation and ROI](https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt). A short text on the current state of AI applications in industry.
- McKinsey & Company (2025). [The state of AI: how organizations are rewiring to capture value](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai). A business-focused overview of AI adoption and impact.

### Lecture 2 — A brief history of AI and the recent shift  
From symbolic approaches to data-driven learning; the transformer architecture explained in plain language.

Readings:

- Dick, S. (2019). [Artificial intelligence.](https://doi.org/10.1162/99608f92.92fe150c) *Harvard Data Science Review*, *1*(1). A brief history of AI research and applications. Written for a general audience.
- Grzybowski, A., Pawlikowska–Łagód, K., & Lambert, W. C. (2024). [A history of artificial intelligence.](https://doi.org/10.1016/j.clindermatol.2023.12.016) *Clinics in Dermatology*, *42*(3), 221-229. A "pre-history" overview, focusing on early ideas and milestones.
- Cao, Y., Liu, L., Li, M., Huang, Y., & Li, S. (2023). [A comprehensive survey of AI-generated content (AIGC): A history of generative AI from GAN to ChatGPT.](https://arxiv.org/abs/2303.04226) *arXiv preprint*. A somewhat technical but comprehensive overview of generative AI methods.
- Halevy, A., Norvig, P., & Pereira, F. (2009). [The unreasonable effectiveness of data.](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf) *IEEE Intelligent Systems*, *24*(2), 8-12. A classic paper arguing that large datasets are often more important than sophisticated algorithms.
- Pradhan, M. (2023). [A non-technical introduction to Transformers.](https://medium.com/healthcare-ai-sig/a-non-technical-introduction-to-transformers-6ca36b8246d) A clear explanation of the transformer architecture that underpins many modern AI systems.
- Doshi, K. (2025). [Transformers explained visually, part 1: overview of functionality.](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452/) Another explanation of transformers, with diagrams.
- Horstman, M. (2024). [Transformers for dummies: a peek inside AI models.](https://michielh.medium.com/transformers-unleashed-the-neural-architecture-powering-modern-ai-and-language-models-57626643fd49) _Yet another_ explanation of transformers. This one is a little more technical.
- Georgia Tech's Polo Club of Data Science (2025). [Transformer explainer.](https://poloclub.github.io/transformer-explainer/) An interactive visualisation of how transformers work.

## Module 1 — How AI systems are designed

### Lecture 3 — Dataset design, labels, and tasks  
What data are, how tasks are framed, and common pitfalls in dataset design.  

Readings:

- Athalye, A., Northcutt, C., & Mueller, J. (2024). [Dataset creation and curation](https://dcai.csail.mit.edu/2024/dataset-creation-curation/) in *Data-Centric AI*. A chapter from a forthcoming book on data-centric AI, covering the main ideas in dataset design.
- Sapien Labs. (2024). [Labeling data for machine learning: best practices and quality control.](https://www.sapien.io/blog/labeling-data-for-machine-learning-best-practices-and-quality-control) A practical guide to data labeling, with tips and common pitfalls.
- Liang, W., Tadesse, G. A., Ho, D., Fei-Fei, L., Zaharia, M., Zhang, C., & Zou, J. (2022). [Advances, challenges and opportunities in creating data for trustworthy AI.](https://www.nature.com/articles/s42256-022-00516-1) *Nature Machine Intelligence*, 4(8), 669-677. A good discussion on the challenges of creating high-quality datasets.
- Orr, W., & Crawford, K. (2024). [The social construction of datasets: on the practices, processes, and challenges of dataset creation for machine learning.](https://journals.sagepub.com/doi/abs/10.1177/14614448241251797) *New Media & Society*, 26(9), 4955-4972. A sociological perspective on dataset creation, with interviews with practitioners.
- Nazer, L. H., Zatarah, R., Waldrip, S., Ke, J. X. C., Moukheiber, M., Khanna, A. K., ... & Mathur, P. (2023). [Bias in artificial intelligence algorithms and recommendations for mitigation.](https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000278) *PLOS Digital Health*, 2(6), e0000278. A review of different types of bias that can arise in datasets and what to do about them. Focused on healthcare but broadly applicable.

### Lecture 4 — Supervised, unsupervised, and hybrid approaches to learning  
What learning means and why generalisation is difficult.

Readings:

- Amazon Web Services (2025). [What is the difference between supervised and unsupervised learning?](https://aws.amazon.com/compare/the-difference-between-machine-learning-supervised-and-unsupervised/) A practical overview of supervised and unsupervised learning, with examples.
- Lee, F. (2025). [What is bias-variance tradeoff?](https://www.ibm.com/think/topics/bias-variance-tradeoff) An explanation of a key concept in machine learning. It has some formulas but the main ideas are easy to grasp.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). [Chapter 5: Machine learning basics](https://www.deeplearningbook.org/contents/ml.html) in *Deep Learning*. A technical but clear introduction to the main ideas behind machine learning.
- Elsevier (2025). [Science direct: supervised learning.](https://www.sciencedirect.com/topics/computer-science/supervised-learning) A short introduction to supervised learning, with links to further readings.
- Elsevier (2025). [Science direct: unsupervised learning.](https://www.sciencedirect.com/topics/computer-science/unsupervised-learning) Same as above, but for unsupervised learning.

### Lecture 5 — Metrics, validation and overfitting 

Confusion matrices, precision and recall, cross-validation and the limits of single-number metrics.

Readings:

- Akinkugbe, A. (2025). [The essential guide to model evaluation metrics for classification.](https://pub.towardsai.net/the-essential-guide-to-model-evaluation-metrics-for-classification-560efee6f445) A practical guide to common evaluation metrics, with examples and case studies.
- Thomas, R. L., & Uminsky, D. (2022). [Reliance on metrics is a fundamental challenge for AI.](https://www.cell.com/patterns/fulltext/S2666-3899(22)00056-3) *Patterns*, 3(5).100440. A discussion of the limitations of metrics and how they can be gamed or misinterpreted.
- Montesinos López, O. A., Montesinos López, A., & Crossa, J. (2022). [Overfitting, model tuning, and evaluation of prediction performance.](https://link.springer.com/chapter/10.1007/978-3-030-89010-0_4) In *Multivariate statistical machine learning methods for genomic prediction* (pp. 109-139). Cham: Springer International Publishing. Good chapter, worth reading even if you don't understand all the maths.
- Coursera (2025). [Precision vs. recall in machine learning: what's the difference?](https://www.coursera.org/articles/precision-vs-recall-machine-learning). A short article about those two commonly confused metrics.
- Palumbo, G., Carneiro, D., & Alves, V. (2024). [Objective metrics for ethical AI: a systematic literature review.](https://link.springer.com/article/10.1007/s41060-024-00541-w) *International Journal of Data Science and Analytics*, 1-21. New ideas about how to evaluate AI systems beyond accuracy.

### Lecture 6 — Quiz 1  

## Module 2 — Language and perception

### Lecture 7 — How machines handle language: tokens, embeddings and context  
An intuitive view of tokenisation, vector representations and contextual meaning.

Readings:
- Neptune.ai (2025). [The ultimate guide to word embeddings.](https://neptune.ai/blog/word-embeddings-guide) The title is a bit grandiose, but this is a clear and practical introduction to word embeddings. Includes Python code snippets.
- Neptune.ai (2025). [Tokenization in NLP: types, challenges, examples, tools.](https://neptune.ai/blog/tokenization-in-nlp) Another article by the same group, this time on tokenisation. Also includes code snippets.
- StackOverflow (2023). [An intuitive introduction to text embeddings.](https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/) A practical introduction to embeddings, with simple examples.
- DeepLearning.ai (2023). [A complete guide to natural language processing.](https://www.deeplearning.ai/resources/natural-language-processing/) Despite another grandiose title, this is a good overview of NLP concepts and techniques.
- Gastaldi, J. L., Terilla, J., Malagutti, L., DuSell, B., Vieira, T., & Cotterell, R. (2024). [The foundations of tokenization: statistical and computational concerns.](https://arxiv.org/abs/2407.11606) *arXiv preprint* arXiv:2407.11606. Very technical, for those interested in the mathematical details of tokenisation.

### Lecture 8 — How machines analyse images and audio  
Abstraction, convolution and the role of large datasets.

Readings:
- O'Shea, K., & Nash, R. (2015). [An introduction to convolutional neural networks.](https://arxiv.org/abs/1511.08458) *arXiv preprint* arXiv:1511.08458. A clear and concise tutorial.
- DataCamp (2025). [What is computer vision? A beginner guide to image analysis.](https://www.datacamp.com/blog/what-is-computer-vision) Simple and illustrated introduction to computer vision concepts.
- AltexSoft (2025). [How AI sound, music, and voice generation works.](https://www.altexsoft.com/blog/sound-music-voice-generation/) Another practical introduction. A nice reading!
- Singal, A. (2023). [Hearing is believing: revolutionizing AI with audio classification via computer vision.](https://huggingface.co/blog/Andyrasika/voice-with-vision) How machines classify audio using image-based techniques. Includes Python code for practitioners.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). [Deep learning.](https://www.deeplearningbook.org/) MIT Press. Chapters 9 and 10 provide a solid foundation in convolutional networks. A bit technical, quite dense, but this is one of the best books on deep learning.

### Lecture 9 — Behavioural testing: examples and demonstrations  
Live demos: prompt responses, image classifiers, and stress-tests.  

No required readings for this lecture. We will do live demonstrations in class.

### Lecture 10 — Quiz 2  
Covers Lectures 7–9.

## Module 3 — Retrieval, generation and pipelines

### Lecture 11 — Retrieval-augmented workflows and semantic search  
Augmenting generation with retrieval; vector search and chunking explained for practitioners.

Readings:

- Amazon Web Services (2025). [What is retrieval-augmented generation (RAG)?](https://aws.amazon.com/what-is/retrieval-augmented-generation/) Beginners' guide to RAG by people who know what they're talking about.
- Erikson, J. (2024). [What is vector search? The ultimate guide.](https://aws.amazon.com/what-is/retrieval-augmented-generation/) Yes, the grandiose titles are a trend. The article is pretty good, though.
- Mastering LLM (2024). [11 chunking strategies for RAG — simplified & visualized](https://masteringllm.medium.com/11-chunking-strategies-for-rag-simplified-visualized-df0dbec8e373) Very nice explanation of chunking strategies, with diagrams.
- Slack (2025). [Semantic search explained: how it works, and why it matters.](https://slack.com/blog/productivity/semantic-search-explained-how-it-works-and-why-it-matters) Good explainer from a top tech company.
- Wang, X., Wang, Z., Gao, X., Zhang, F., Wu, Y., Xu, Z., ... & Huang, X. (2024). [Searching for best practices in retrieval-augmented generation.](https://arxiv.org/abs/2407.01219) *arXiv preprint* arXiv:2407.01219. Technical in nature, for those interested in the research behind RAG.

### Lecture 12 — Creativity and hallucination  
Why models invent facts and how to spot and reduce hallucination.

Readings:

- Jiang, X., Tian, Y., Hua, F., Xu, C., Wang, Y., & Guo, J. (2024). [A survey on large language model hallucination via a creativity perspective.](https://arxiv.org/abs/2402.06647) *arXiv preprint* arXiv:2402.06647. Very nice article showing how hallucinations can be used creatively.
- Tonmoy, S. M. T. I., Zaman, S. M., Jain, V., Rani, A., Rawte, V., Chadha, A., & Das, A. (2024). [A comprehensive survey of hallucination mitigation techniques in large language models.](https://arxiv.org/abs/2401.01313) *arXiv preprint* arXiv:2401.01313, 6. The article is quite detailed and lists a series of techniques to reduce hallucinations. No need to know them all, just to know they exist and how they work in principle.
- Wikipedia (2025). [Hallucination (artificial intelligence).](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)) Wikipedia actually has some good articles on AI topics. This one is a well-written overview of hallucinations.
- Chakraborty, T., & Masud, S. (2024). [The promethean dilemma of AI at the intersection of hallucination and creativity.](https://cacm.acm.org/opinion/the-promethean-dilemma-of-ai-at-the-intersection-of-hallucination-and-creativity/) *Communications of the ACM*, 67(10), 26-28. Full of interesting ideas and perspectives.
- OpenAI (2024). [Does ChatGPT tell the truth?](https://help.openai.com/en/articles/8313428-does-chatgpt-tell-the-truth) I'm sure you know who these people are. Practical advice.
- Kalai, A. T., Nachum, O., Vempala, S. S., & Zhang, E. (2025). [Why language models hallucinate.](https://arxiv.org/abs/2509.04664) *arXiv preprint* arXiv:2509.04664. Written by members of OpenAI. Not for the faint of heart by any means, but if you're feeling adventurous...

### Lecture 13 — Building reliable pipelines: monitoring and testing  
Overview of simple strategies for AI evaluation; what operational teams track.  

Readings:

- Google (2025). [Production ML systems: monitoring pipelines.](https://developers.google.com/machine-learning/crash-course/production-ml-systems/monitoring) If there's one company that knows how to run ML systems at scale, it's Google. This is a practical guide to monitoring ML pipelines. If you are unfamiliar with some terms, don't worry too much; the main ideas are easy to grasp. Use AI to help you if needed!
- Allen, J. (2024). [Data pipeline monitoring: best practices for full observability.](https://www.prefect.io/blog/data-pipeline-monitoring-best-practices) Informal and full of practical tips. Some technical terms too, but nothing too difficult.
- Steidl, M., Felderer, M., & Ramler, R. (2023). [The pipeline for the continuous development of artificial intelligence models--current state of research and practice.](https://arxiv.org/abs/2301.09001) *arXiv e-prints*, arXiv-2301. _Super long_ article (sorry!), but it covers everything we discuss in class and more. Just read what you need.

### Lecture 14 — Quiz 3  
Covers Lectures 11–13.

## Module 4 — Data ethics and bias

### Lecture 15 — Types of bias and how they arise  
Selection bias, label bias and measurement error.

Readings:

- Barocas, S., Hardt, M., & Narayanan, A. (2019). [Fairness and machine learning](https://fairmlbook.org/). Chapter 2: When is automated decision making legitimate? A very good book on fairness in machine learning. This chapter covers the main types of bias that can arise in datasets.
- Mehrabi, N., Morstatter, F., Saxena, N., Lettich, A., & Galstyan, A. (2021). [A survey on bias and fairness in machine learning.](https://arxiv.org/abs/1908.09635) *ACM Computing Surveys (CSUR)*, *54*(6), 1-35. A comprehensive survey of bias and fairness in machine learning. Quite technical, but the introduction and conclusion are accessible.
- Suresh, H., & Guttag, J. V. (2019). [A framework for understanding unintended consequences of machine learning.](https://dl.acm.org/doi/10.1145/3287560.3287598) In *Conference on Fairness, Accountability, and Transparency* (pp. 1-10). A good framework for thinking about biases.
- Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). [On the dangers of stochastic parrots: Can language models be too big?](https://dl.acm.org/doi/10.1145/3442188.3445922) In *Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency* (pp. 610-623). A critical look at large language models and the risks they pose.
- Silberg, J., & Manyika, J. (2019). [Notes from the AI frontier: tackling bias in AI (and in humans).](https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/Artificial%20Intelligence/Tackling%20bias%20in%20artificial%20intelligence%20and%20in%20humans/MGI-Tackling-bias-in-AI-June-2019.pdf) McKinsey Global Institute, 1(6), 1-31. An easy-to-read report on bias in AI, with practical recommendations for business and policy.

### Lecture 16 — Documentation and dataset governance  
Datasheets, model cards and provenance.  

Readings:
- Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K. (2018). [Datasheets for datasets.](https://arxiv.org/abs/1803.09010) *arXiv preprint* arXiv:1803.09010. The original paper proposing datasheets for datasets.
- Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., ... & Gebru, T. (2019). [Model cards for model reporting.](https://arxiv.org/abs/1810.03993) *Proceedings of the Conference on Fairness, Accountability, and Transparency* (pp. 220-229). The original paper proposing model cards.
- Bender, E. M., & Friedman, B. (2018). [Data statements for natural language processing: Toward mitigating system bias and enabling better science.](https://www.aclweb.org/anthology/Q18-1041/) In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing* (pp. 1-14). A proposal for data statements to accompany NLP datasets.
- IBM (2025). [What is data lineage?](https://www.ibm.com/think/topics/data-lineage) A short guide to data lineage, with use cases.
- IBM (2025). [What is data provenance?](https://www.ibm.com/topics/data-provenance) Another practical guide, this time on data provenance.

### Lecture 17 — Case studies: biased outcomes in health, hiring and policing  
Examples that illustrate impact and possible mitigations.

Readings:
- Rudin, C. (2019). [Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead.](https://www.nature.com/articles/s42256-019-0048-x) *Nature machine intelligence*, 1(5), 206-215. A strong argument for using interpretable models in important aspects of life.
- Obermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S. (2019). [Dissecting racial bias in an algorithm used to manage the health of populations.](https://science.sciencemag.org/content/366/6464/447) *Science*, *366*(6464), 447-453. A landmark study showing how a widely used health algorithm exhibited racial bias.
- Buolamwini, J., & Gebru, T. (2018). [Gender shades: Intersectional accuracy disparities in commercial gender classification.](http://proceedings.mlr.press/v81/buolamwini18a.html) *Proceedings of Machine Learning Research*, *81*, 1-15. A study revealing bias in facial recognition systems.
- Angwin, J., Larson, J., Mattu, S., & Kirchner, L. (2016). [Machine bias: There's software used across the country to predict future criminals. And it's biased against blacks.](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) *ProPublica*. A widely cited investigation into bias in criminal risk assessment tools.
- Wilson, K., & Caliskan, A. (2024, October). [Gender, race, and intersectional bias in resume screening via language model retrieval.](https://ojs.aaai.org/index.php/AIES/article/view/31748) In *Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society* (Vol. 7, pp. 1578-1590). A recent paper on how AI may be biased in hiring.
- AI Now Institute (2025). [Artificial Power: 2025 Landscape Report.](https://ainowinstitute.org/publications/research/ai-now-2025-landscape-report) A strongly critical report on the power dynamics in the AI ecosystem. Worth reading even if you disagree with the arguments.

### Lecture 18 — Quiz 4  
Covers Lectures 15–17.

## Module 5 — Policy, governance and social impact

### Lecture 19 — AI regulation and standards around the world  
American AI Initiative, OECD principles, EU AI Act summary and how rules influence design.

Readings:

- The White House. (2025). [Winning the race: America's AI action plan](https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf). What the US government wants to do about AI.
- OECD. (2019). [OECD AI principles](https://oecd.ai/en/ai-principles). The original text of the OECD AI principles. Just skim the main points.
- OECD. (2024). [Recommendation of the council on artificial intelligence](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449). Again, just skim the main points.
- European Parliament. (2023). [EU AI act](https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence). The original text. 
- Cole, M. D. (2024). [AI regulation and governance on a global scale: An overview of international, regional and national instruments.](https://web.archive.org/web/20240330165240id_/https://aire.lexxion.eu/data/article/19406/pdf/aire_2024_01-017.pdf) *Journal of AI Law and Regulation*, *1*(1), 126-142. How different countries are approaching AI regulation.
- Chun, J., de Witt, C. S., & Elkins, K. (2024). [Comparative global AI regulation: Policy perspectives from the EU, China, and the US.](https://arxiv.org/pdf/2410.21279) *arXiv preprint*. Focused on the big three players in AI regulation.
- Feldstein, S. (2024). [Evaluating Europe's push to enact AI regulations: How will this influence global norms?](https://www.tandfonline.com/doi/pdf/10.1080/13510347.2023.2196068) *Democratization*, *31*(5), 1049-1066. Will the EU's approach to AI regulation become a global standard?

### Lecture 20 — Privacy and data protection  
Practical implications of GDPR-style rules for datasets and deployed systems.

Readings:

- European Union. (2016). [General Data Protection Regulation (GDPR).](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679) The original text of the GDPR. Don't worry about reading the whole thing; just skim the main points.
- Hoofnagle, C. J., Van Der Sloot, B., & Borgesius, F. Z. (2019). [The European Union general data protection regulation: what it is and what it means.](https://www.tandfonline.com/doi/full/10.1080/13600834.2019.1573501) *Information & Communications Technology Law*, 28(1), 65-98. Much easier to read than the original GDPR text. Read this one instead if you want a summary.
- Wachter, S., Mittelstadt, B., & Floridi, L. (2017). [Why a right to explanation of automated decision-making does not exist in the general data protection regulation.](https://doi.org/10.1093/idpl/ipx005) *International data privacy law*, 7(2), 76-99. A critical look at the "right to explanation" in GDPR.
- Ryngaert, C., & Taylor, M. (2020). [The GDPR as Global Data Protection Regulation?](https://www.cambridge.org/core/journals/american-journal-of-international-law/article/gdpr-as-global-data-protection-regulation/CB416FF11457C21B02C0D1DA7BE8E688) *AJIL Unbound*, 114, 5-9. A discussion of the GDPR's (possible) influence beyond the EU.
- Taddeo, M., & Floridi, L. (2018). [How AI can be a force for good.](https://www.science.org/doi/abs/10.1126/science.aat5991) *Science*, 361(6404), 751-752. A positive perspective on how AI can be used ethically and responsibly.

### Lecture 21 — Labour markets and economic effects  
How automation affects jobs; augmentation strategies and policy responses.  

Readings:

- Korinek, A., & Suh, D. (2024). [Scenarios for the Transition to AGI (No. w32255).](https://www.nber.org/system/files/working_papers/w32255/w32255.pdf) National Bureau of Economic Research. How output and wages behave under different scenarios for technological progress.
- Acemoglu, D., & Restrepo, P. (2019). [Automation and new tasks: How technology displaces and reinstates labor.](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3) *Journal of Economic Perspectives*, 33(2), 3-30. A comprehensive review of how automation affects jobs.
- Restrepo, P. (2025). [We won't be missed: work and growth in the era of AGI.](https://www.nber.org/books-and-chapters/economics-transformative-ai/we-wont-be-missed-work-and-growth-era-agi) NBER Chapters. Some scholars suggest we will live in an age of abundance, others that we will all be unemployed. What if the truth is somewhere in between?
- Bessen, J. E. (2019). [AI and jobs: The role of demand.](https://www.nber.org/papers/w24235) *NBER Working Paper* No. 24235. A nuanced look at how AI affects labour markets, focusing on demand-side effects.
- World Economic Forum. (2025). [The future of jobs report 2025.](https://www.weforum.org/reports/the-future-of-jobs-report-2025) A comprehensive report on how jobs are expected to change in the last years.
- Manyika, J., Chui, M., Miremadi, M., Bughin, J., George, K., Willmott, P., & Dewhurst, M. (2017). [A future that works: Automation, employment, and productivity.](https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/Digital%20Disruption/Harnessing%20automation%20for%20a%20future%20that%20works/mgi-a-future-that-works-full-report-updated.pdf) McKinsey Global Institute. A widely cited report on automation and jobs.

### Lecture 22 — Quiz 5  
Covers Lectures 19–21.

## Module 6 — Applications, limits and projects

### Lecture 23 — AI in health, education and public services  
Risks and benefits for public-sector applications.

Readings:
- Davenport, T., & Kalakota, R. (2019). [The potential for artificial intelligence in healthcare.](https://www.sciencedirect.com/science/article/pii/S2514664524010592) *Future healthcare journal*, 6(2), 94-98.
- Aung, Y. Y., Wong, D. C., & Ting, D. S. (2021). [The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare.](https://academic.oup.com/bmb/advance-article-pdf/doi/10.1093/bmb/ldab016/40343944/ldab016.pdf) *British medical bulletin*, 139(1), 4-15. This article complements the previous one.
- Zhai, X., Chu, X., Chai, C. S., Jong, M. S. Y., Istenic, A., Spector, M., ... & Li, Y. (2021). [A review of artificial intelligence (AI) in education from 2010 to 2020.](https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/8812542) *Complexity*, 2021(1), 8812542. A comprehensive review on that topic.
- Alasadi, E. A., & Baiz, C. R. (2023). [Generative AI in Education and Research: Opportunities, concerns, and solutions.](https://doi.org/10.1021/acs.jchemed.3c00323) *Journal of Chemical Education*, *100* (8), 2965-2971.
- Osborne, S. P., Cucciniello, M., Nasi, G., & Zhu, E. (2022). [Digital transformation, artificial intelligence and effective public services: challenges and opportunities.](https://link.springer.com/article/10.1007/s43508-022-00058-7) *Global Public Policy Governance*, *2*(4), 377-380. This is the introduction of a special issue on AI in public services. The whole issue is worth reading.

### Lecture 24 — Misinformation, deepfakes and trust online  
Technical features and societal responses to synthetic media.

Readings:
- Helmus, T. C. (2022). [Artificial intelligence, deepfakes, and disinformation: A primer.](https://www.rand.org/pubs/perspectives/PEA1043-1.html) *RAND Corporation*. Very accessible introduction to the topic.
- Mustak, M., Salminen, J., Mäntymäki, M., Rahman, A., & Dwivedi, Y. K. (2023). [Deepfakes: Deceptions, mitigations, and opportunities.](https://doi.org/10.1016/j.jbusres.2022.113368) *Journal of Business Research*, 154, 113368. Focused on business applications.
- Chesney, R., & Citron, D. K. (2019). [Deepfakes and the new disinformation war: The coming age of post-truth geopolitics.](https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-war) *Foreign Affairs*. A legal perspective on deepfakes and misinformation.
- Vaccari, C., & Chadwick, A. (2020). [Deepfakes and disinformation: Exploring the impact of synthetic political video on deception, uncertainty, and trust in news.](https://journals.sagepub.com/doi/full/10.1176305120903408) *Social Media + Society*, *6*(1), 2056305120903408. An empirical study that finds that deepfakes may contribute toward generalised indeterminacy and cynicism.
- Kietzmann, J., Lee, L. W., McCarthy, I. P., & Kietzmann, T. C. (2020). [Deepfakes: Trick or treat?](https://doi.org/10.1016/j.bushor.2019.11.006) *Business Horizons*, 63(2), 135-146. The authors provide a framework to manage deepfake risks. 

### Lecture 25 — Course revision  
Short course revision and Q&A.

### Lecture 26 — Project work  
In-class time for project work and consultations.