[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2026 Danilo Freire\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Please find below the schedule of our lectures. Each lecture includes a brief description and required readings. The lecture slides and additional resources will be posted on the course website and GitHub repository. Please remember that the schedule may change during the course. If you have any questions or need further assistance, please let me know!"
  },
  {
    "objectID": "lectures.html#module-0-orientation",
    "href": "lectures.html#module-0-orientation",
    "title": "Lectures",
    "section": "Module 0 — Orientation",
    "text": "Module 0 — Orientation\n\nLecture 1 — Course introduction; what AI means today\nSyllabus, assessment, expectations. A factual tour of AI in products and media and the questions we will address.\nReadings:\n\nStanford University’s Human-Centered Artificial Intelligence (2025). AI Index Annual Report. An excellent report on the state of AI, with many useful charts and references.\nOur World in Data (2025). Artificial intelligence. A concise overview of AI trends and applications, with links to further resources.\nMenlo Ventures (2025). 2025: the state of consumer AI. How AI is being used in consumer products, with examples and market data.\nMorgan Stanley (2025). AI’s next leap: 5 trends shaping innovation and ROI. A short text on the current state of AI applications in industry.\nMcKinsey & Company (2025). The state of AI: how organizations are rewiring to capture value. A business-focused overview of AI adoption and impact.\n\n\n\nLecture 2 — A brief history of AI and the recent shift\nFrom symbolic approaches to data-driven learning; the transformer architecture explained in plain language.\nReadings:\n\nDick, S. (2019). Artificial intelligence. Harvard Data Science Review, 1(1). A brief history of AI research and applications. Written for a general audience.\nGrzybowski, A., Pawlikowska–Łagód, K., & Lambert, W. C. (2024). A history of artificial intelligence. Clinics in Dermatology, 42(3), 221-229. A “pre-history” overview, focusing on early ideas and milestones.\nCao, Y., Liu, L., Li, M., Huang, Y., & Li, S. (2023). A comprehensive survey of AI-generated content (AIGC): A history of generative AI from GAN to ChatGPT. arXiv preprint. A somewhat technical but comprehensive overview of generative AI methods.\nHalevy, A., Norvig, P., & Pereira, F. (2009). The unreasonable effectiveness of data. IEEE Intelligent Systems, 24(2), 8-12. A classic paper arguing that large datasets are often more important than sophisticated algorithms.\nPradhan, M. (2023). A non-technical introduction to Transformers. A clear explanation of the transformer architecture that underpins many modern AI systems.\nDoshi, K. (2025). Transformers explained visually, part 1: overview of functionality. Another explanation of transformers, with diagrams.\nHorstman, M. (2024). Transformers for dummies: a peek inside AI models. Yet another explanation of transformers. This one is a little more technical.\nGeorgia Tech’s Polo Club of Data Science (2025). Transformer explainer. An interactive visualisation of how transformers work."
  },
  {
    "objectID": "lectures.html#module-1-how-ai-systems-are-designed",
    "href": "lectures.html#module-1-how-ai-systems-are-designed",
    "title": "Lectures",
    "section": "Module 1 — How AI systems are designed",
    "text": "Module 1 — How AI systems are designed\n\nLecture 3 — Dataset design, labels, and tasks\nWhat data are, how tasks are framed, and common pitfalls in dataset design.\nReadings:\n\nAthalye, A., Northcutt, C., & Mueller, J. (2024). Dataset creation and curation in Data-Centric AI. A chapter from a forthcoming book on data-centric AI, covering the main ideas in dataset design.\nSapien Labs. (2024). Labeling data for machine learning: best practices and quality control. A practical guide to data labeling, with tips and common pitfalls.\nLiang, W., Tadesse, G. A., Ho, D., Fei-Fei, L., Zaharia, M., Zhang, C., & Zou, J. (2022). Advances, challenges and opportunities in creating data for trustworthy AI. Nature Machine Intelligence, 4(8), 669-677. A good discussion on the challenges of creating high-quality datasets.\nOrr, W., & Crawford, K. (2024). The social construction of datasets: on the practices, processes, and challenges of dataset creation for machine learning. New Media & Society, 26(9), 4955-4972. A sociological perspective on dataset creation, with interviews with practitioners.\nNazer, L. H., Zatarah, R., Waldrip, S., Ke, J. X. C., Moukheiber, M., Khanna, A. K., … & Mathur, P. (2023). Bias in artificial intelligence algorithms and recommendations for mitigation. PLOS Digital Health, 2(6), e0000278. A review of different types of bias that can arise in datasets and what to do about them. Focused on healthcare but broadly applicable.\n\n\n\nLecture 4 — Supervised, unsupervised, and hybrid approaches to learning\nWhat learning means and why generalisation is difficult.\nReadings:\n\nAmazon Web Services (2025). What is the difference between supervised and unsupervised learning? A practical overview of supervised and unsupervised learning, with examples.\nLee, F. (2025). What is bias-variance tradeoff? An explanation of a key concept in machine learning. It has some formulas but the main ideas are easy to grasp.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Chapter 5: Machine learning basics in Deep Learning. A technical but clear introduction to the main ideas behind machine learning.\nElsevier (2025). Science direct: supervised learning. A short introduction to supervised learning, with links to further readings.\nElsevier (2025). Science direct: unsupervised learning. Same as above, but for unsupervised learning.\n\n\n\nLecture 5 — Metrics, validation and overfitting\nConfusion matrices, precision and recall, cross-validation and the limits of single-number metrics.\nReadings:\n\nAkinkugbe, A. (2025). The essential guide to model evaluation metrics for classification. A practical guide to common evaluation metrics, with examples and case studies.\nThomas, R. L., & Uminsky, D. (2022). Reliance on metrics is a fundamental challenge for AI. Patterns, 3(5).100440. A discussion of the limitations of metrics and how they can be gamed or misinterpreted.\nMontesinos López, O. A., Montesinos López, A., & Crossa, J. (2022). Overfitting, model tuning, and evaluation of prediction performance. In Multivariate statistical machine learning methods for genomic prediction (pp. 109-139). Cham: Springer International Publishing. Good chapter, worth reading even if you don’t understand all the maths.\nCoursera (2025). Precision vs. recall in machine learning: what’s the difference?. A short article about those two commonly confused metrics.\nPalumbo, G., Carneiro, D., & Alves, V. (2024). Objective metrics for ethical AI: a systematic literature review. International Journal of Data Science and Analytics, 1-21. New ideas about how to evaluate AI systems beyond accuracy.\n\n\n\nLecture 6 — Quiz 1"
  },
  {
    "objectID": "lectures.html#module-2-language-and-perception",
    "href": "lectures.html#module-2-language-and-perception",
    "title": "Lectures",
    "section": "Module 2 — Language and perception",
    "text": "Module 2 — Language and perception\n\nLecture 7 — How machines handle language: tokens, embeddings and context\nAn intuitive view of tokenisation, vector representations and contextual meaning.\nReadings: - Neptune.ai (2025). The ultimate guide to word embeddings. The title is a bit grandiose, but this is a clear and practical introduction to word embeddings. Includes Python code snippets. - Neptune.ai (2025). Tokenization in NLP: types, challenges, examples, tools. Another article by the same group, this time on tokenisation. Also includes code snippets. - StackOverflow (2023). An intuitive introduction to text embeddings. A practical introduction to embeddings, with simple examples. - DeepLearning.ai (2023). A complete guide to natural language processing. Despite another grandiose title, this is a good overview of NLP concepts and techniques. - Gastaldi, J. L., Terilla, J., Malagutti, L., DuSell, B., Vieira, T., & Cotterell, R. (2024). The foundations of tokenization: statistical and computational concerns. arXiv preprint arXiv:2407.11606. Very technical, for those interested in the mathematical details of tokenisation.\n\n\nLecture 8 — How machines analyse images and audio\nAbstraction, convolution and the role of large datasets.\nReadings: - O’Shea, K., & Nash, R. (2015). An introduction to convolutional neural networks. arXiv preprint arXiv:1511.08458. A clear and concise tutorial. - DataCamp (2025). What is computer vision? A beginner guide to image analysis. Simple and illustrated introduction to computer vision concepts. - AltexSoft (2025). How AI sound, music, and voice generation works. Another practical introduction. A nice reading! - Singal, A. (2023). Hearing is believing: revolutionizing AI with audio classification via computer vision. How machines classify audio using image-based techniques. Includes Python code for practitioners. - Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press. Chapters 9 and 10 provide a solid foundation in convolutional networks. A bit technical, quite dense, but this is one of the best books on deep learning.\n\n\nLecture 9 — Behavioural testing: examples and demonstrations\nLive demos: prompt responses, image classifiers, and stress-tests.\nNo required readings for this lecture. We will do live demonstrations in class.\n\n\nLecture 10 — Quiz 2\nCovers Lectures 7–9."
  },
  {
    "objectID": "lectures.html#module-3-retrieval-generation-and-pipelines",
    "href": "lectures.html#module-3-retrieval-generation-and-pipelines",
    "title": "Lectures",
    "section": "Module 3 — Retrieval, generation and pipelines",
    "text": "Module 3 — Retrieval, generation and pipelines\n\nLecture 11 — Retrieval-augmented workflows and semantic search\nAugmenting generation with retrieval; vector search and chunking explained for practitioners.\nReadings:\n\nAmazon Web Services (2025). What is retrieval-augmented generation (RAG)? Beginners’ guide to RAG by people who know what they’re talking about.\nErikson, J. (2024). What is vector search? The ultimate guide. Yes, the grandiose titles are a trend. The article is pretty good, though.\nMastering LLM (2024). 11 chunking strategies for RAG — simplified & visualized Very nice explanation of chunking strategies, with diagrams.\nSlack (2025). Semantic search explained: how it works, and why it matters. Good explainer from a top tech company.\nWang, X., Wang, Z., Gao, X., Zhang, F., Wu, Y., Xu, Z., … & Huang, X. (2024). Searching for best practices in retrieval-augmented generation. arXiv preprint arXiv:2407.01219. Technical in nature, for those interested in the research behind RAG.\n\n\n\nLecture 12 — Creativity and hallucination\nWhy models invent facts and how to spot and reduce hallucination.\nReadings:\n\nJiang, X., Tian, Y., Hua, F., Xu, C., Wang, Y., & Guo, J. (2024). A survey on large language model hallucination via a creativity perspective. arXiv preprint arXiv:2402.06647. Very nice article showing how hallucinations can be used creatively.\nTonmoy, S. M. T. I., Zaman, S. M., Jain, V., Rani, A., Rawte, V., Chadha, A., & Das, A. (2024). A comprehensive survey of hallucination mitigation techniques in large language models. arXiv preprint arXiv:2401.01313, 6. The article is quite detailed and lists a series of techniques to reduce hallucinations. No need to know them all, just to know they exist and how they work in principle.\nWikipedia (2025). Hallucination (artificial intelligence). Wikipedia actually has some good articles on AI topics. This one is a well-written overview of hallucinations.\nChakraborty, T., & Masud, S. (2024). The promethean dilemma of AI at the intersection of hallucination and creativity. Communications of the ACM, 67(10), 26-28. Full of interesting ideas and perspectives.\nOpenAI (2024). Does ChatGPT tell the truth? I’m sure you know who these people are. Practical advice.\nKalai, A. T., Nachum, O., Vempala, S. S., & Zhang, E. (2025). Why language models hallucinate. arXiv preprint arXiv:2509.04664. Written by members of OpenAI. Not for the faint of heart by any means, but if you’re feeling adventurous…\n\n\n\nLecture 13 — Building reliable pipelines: monitoring and testing\nOverview of simple strategies for AI evaluation; what operational teams track.\nReadings:\n\nGoogle (2025). Production ML systems: monitoring pipelines. If there’s one company that knows how to run ML systems at scale, it’s Google. This is a practical guide to monitoring ML pipelines. If you are unfamiliar with some terms, don’t worry too much; the main ideas are easy to grasp. Use AI to help you if needed!\nAllen, J. (2024). Data pipeline monitoring: best practices for full observability. Informal and full of practical tips. Some technical terms too, but nothing too difficult.\nSteidl, M., Felderer, M., & Ramler, R. (2023). The pipeline for the continuous development of artificial intelligence models–current state of research and practice. arXiv e-prints, arXiv-2301. Super long article (sorry!), but it covers everything we discuss in class and more. Just read what you need.\n\n\n\nLecture 14 — Quiz 3\nCovers Lectures 11–13."
  },
  {
    "objectID": "lectures.html#module-4-data-ethics-and-bias",
    "href": "lectures.html#module-4-data-ethics-and-bias",
    "title": "Lectures",
    "section": "Module 4 — Data ethics and bias",
    "text": "Module 4 — Data ethics and bias\n\nLecture 15 — Types of bias and how they arise\nSelection bias, label bias and measurement error.\nReadings:\n\nBarocas, S., Hardt, M., & Narayanan, A. (2019). Fairness and machine learning. Chapter 2: When is automated decision making legitimate? A very good book on fairness in machine learning. This chapter covers the main types of bias that can arise in datasets.\nMehrabi, N., Morstatter, F., Saxena, N., Lettich, A., & Galstyan, A. (2021). A survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR), 54(6), 1-35. A comprehensive survey of bias and fairness in machine learning. Quite technical, but the introduction and conclusion are accessible.\nSuresh, H., & Guttag, J. V. (2019). A framework for understanding unintended consequences of machine learning. In Conference on Fairness, Accountability, and Transparency (pp. 1-10). A good framework for thinking about biases.\nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). A critical look at large language models and the risks they pose.\nSilberg, J., & Manyika, J. (2019). Notes from the AI frontier: tackling bias in AI (and in humans). McKinsey Global Institute, 1(6), 1-31. An easy-to-read report on bias in AI, with practical recommendations for business and policy.\n\n\n\nLecture 16 — Documentation and dataset governance\nDatasheets, model cards and provenance.\nReadings: - Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K. (2018). Datasheets for datasets. arXiv preprint arXiv:1803.09010. The original paper proposing datasheets for datasets. - Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., … & Gebru, T. (2019). Model cards for model reporting. Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 220-229). The original paper proposing model cards. - Bender, E. M., & Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 1-14). A proposal for data statements to accompany NLP datasets. - IBM (2025). What is data lineage? A short guide to data lineage, with use cases. - IBM (2025). What is data provenance? Another practical guide, this time on data provenance.\n\n\nLecture 17 — Case studies: biased outcomes in health, hiring and policing\nExamples that illustrate impact and possible mitigations.\nReadings: - Rudin, C. (2019). Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature machine intelligence, 1(5), 206-215. A strong argument for using interpretable models in important aspects of life. - Obermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S. (2019). Dissecting racial bias in an algorithm used to manage the health of populations. Science, 366(6464), 447-453. A landmark study showing how a widely used health algorithm exhibited racial bias. - Buolamwini, J., & Gebru, T. (2018). Gender shades: Intersectional accuracy disparities in commercial gender classification. Proceedings of Machine Learning Research, 81, 1-15. A study revealing bias in facial recognition systems. - Angwin, J., Larson, J., Mattu, S., & Kirchner, L. (2016). Machine bias: There’s software used across the country to predict future criminals. And it’s biased against blacks. ProPublica. A widely cited investigation into bias in criminal risk assessment tools. - Wilson, K., & Caliskan, A. (2024, October). Gender, race, and intersectional bias in resume screening via language model retrieval. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (Vol. 7, pp. 1578-1590). A recent paper on how AI may be biased in hiring. - AI Now Institute (2025). Artificial Power: 2025 Landscape Report. A strongly critical report on the power dynamics in the AI ecosystem. Worth reading even if you disagree with the arguments.\n\n\nLecture 18 — Quiz 4\nCovers Lectures 15–17."
  },
  {
    "objectID": "lectures.html#module-5-policy-governance-and-social-impact",
    "href": "lectures.html#module-5-policy-governance-and-social-impact",
    "title": "Lectures",
    "section": "Module 5 — Policy, governance and social impact",
    "text": "Module 5 — Policy, governance and social impact\n\nLecture 19 — AI regulation and standards around the world\nAmerican AI Initiative, OECD principles, EU AI Act summary and how rules influence design.\nReadings:\n\nThe White House. (2025). Winning the race: America’s AI action plan. What the US government wants to do about AI.\nOECD. (2019). OECD AI principles. The original text of the OECD AI principles. Just skim the main points.\nOECD. (2024). Recommendation of the council on artificial intelligence. Again, just skim the main points.\nEuropean Parliament. (2023). EU AI act. The original text.\nCole, M. D. (2024). AI regulation and governance on a global scale: An overview of international, regional and national instruments. Journal of AI Law and Regulation, 1(1), 126-142. How different countries are approaching AI regulation.\nChun, J., de Witt, C. S., & Elkins, K. (2024). Comparative global AI regulation: Policy perspectives from the EU, China, and the US. arXiv preprint. Focused on the big three players in AI regulation.\nFeldstein, S. (2024). Evaluating Europe’s push to enact AI regulations: How will this influence global norms? Democratization, 31(5), 1049-1066. Will the EU’s approach to AI regulation become a global standard?\n\n\n\nLecture 20 — Privacy and data protection\nPractical implications of GDPR-style rules for datasets and deployed systems.\nReadings:\n\nEuropean Union. (2016). General Data Protection Regulation (GDPR). The original text of the GDPR. Don’t worry about reading the whole thing; just skim the main points.\nHoofnagle, C. J., Van Der Sloot, B., & Borgesius, F. Z. (2019). The European Union general data protection regulation: what it is and what it means. Information & Communications Technology Law, 28(1), 65-98. Much easier to read than the original GDPR text. Read this one instead if you want a summary.\nWachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the general data protection regulation. International data privacy law, 7(2), 76-99. A critical look at the “right to explanation” in GDPR.\nRyngaert, C., & Taylor, M. (2020). The GDPR as Global Data Protection Regulation? AJIL Unbound, 114, 5-9. A discussion of the GDPR’s (possible) influence beyond the EU.\nTaddeo, M., & Floridi, L. (2018). How AI can be a force for good. Science, 361(6404), 751-752. A positive perspective on how AI can be used ethically and responsibly.\n\n\n\nLecture 21 — Labour markets and economic effects\nHow automation affects jobs; augmentation strategies and policy responses.\nReadings:\n\nKorinek, A., & Suh, D. (2024). Scenarios for the Transition to AGI (No. w32255). National Bureau of Economic Research. How output and wages behave under different scenarios for technological progress.\nAcemoglu, D., & Restrepo, P. (2019). Automation and new tasks: How technology displaces and reinstates labor. Journal of Economic Perspectives, 33(2), 3-30. A comprehensive review of how automation affects jobs.\nRestrepo, P. (2025). We won’t be missed: work and growth in the era of AGI. NBER Chapters. Some scholars suggest we will live in an age of abundance, others that we will all be unemployed. What if the truth is somewhere in between?\nBessen, J. E. (2019). AI and jobs: The role of demand. NBER Working Paper No. 24235. A nuanced look at how AI affects labour markets, focusing on demand-side effects.\nWorld Economic Forum. (2025). The future of jobs report 2025. A comprehensive report on how jobs are expected to change in the last years.\nManyika, J., Chui, M., Miremadi, M., Bughin, J., George, K., Willmott, P., & Dewhurst, M. (2017). A future that works: Automation, employment, and productivity. McKinsey Global Institute. A widely cited report on automation and jobs.\n\n\n\nLecture 22 — Quiz 5\nCovers Lectures 19–21."
  },
  {
    "objectID": "lectures.html#module-6-applications-limits-and-projects",
    "href": "lectures.html#module-6-applications-limits-and-projects",
    "title": "Lectures",
    "section": "Module 6 — Applications, limits and projects",
    "text": "Module 6 — Applications, limits and projects\n\nLecture 23 — AI in health, education and public services\nRisks and benefits for public-sector applications.\nReadings: - Davenport, T., & Kalakota, R. (2019). The potential for artificial intelligence in healthcare. Future healthcare journal, 6(2), 94-98. - Aung, Y. Y., Wong, D. C., & Ting, D. S. (2021). The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare. British medical bulletin, 139(1), 4-15. This article complements the previous one. - Zhai, X., Chu, X., Chai, C. S., Jong, M. S. Y., Istenic, A., Spector, M., … & Li, Y. (2021). A review of artificial intelligence (AI) in education from 2010 to 2020. Complexity, 2021(1), 8812542. A comprehensive review on that topic. - Alasadi, E. A., & Baiz, C. R. (2023). Generative AI in Education and Research: Opportunities, concerns, and solutions. Journal of Chemical Education, 100 (8), 2965-2971. - Osborne, S. P., Cucciniello, M., Nasi, G., & Zhu, E. (2022). Digital transformation, artificial intelligence and effective public services: challenges and opportunities. Global Public Policy Governance, 2(4), 377-380. This is the introduction of a special issue on AI in public services. The whole issue is worth reading.\n\n\nLecture 24 — Misinformation, deepfakes and trust online\nTechnical features and societal responses to synthetic media.\nReadings: - Helmus, T. C. (2022). Artificial intelligence, deepfakes, and disinformation: A primer. RAND Corporation. Very accessible introduction to the topic. - Mustak, M., Salminen, J., Mäntymäki, M., Rahman, A., & Dwivedi, Y. K. (2023). Deepfakes: Deceptions, mitigations, and opportunities. Journal of Business Research, 154, 113368. Focused on business applications. - Chesney, R., & Citron, D. K. (2019). Deepfakes and the new disinformation war: The coming age of post-truth geopolitics. Foreign Affairs. A legal perspective on deepfakes and misinformation. - Vaccari, C., & Chadwick, A. (2020). Deepfakes and disinformation: Exploring the impact of synthetic political video on deception, uncertainty, and trust in news. Social Media + Society, 6(1), 2056305120903408. An empirical study that finds that deepfakes may contribute toward generalised indeterminacy and cynicism. - Kietzmann, J., Lee, L. W., McCarthy, I. P., & Kietzmann, T. C. (2020). Deepfakes: Trick or treat? Business Horizons, 63(2), 135-146. The authors provide a framework to manage deepfake risks.\n\n\nLecture 25 — Course revision\nShort course revision and Q&A.\n\n\nLecture 26 — Project work\nIn-class time for project work and consultations."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Here you will find information about the assignments for DATASCI 185. There are ten problem sets and five in-class quizzes, along with a final group project. The assignments are designed to help you practice the concepts covered in class and to develop your understanding of AI systems and their applications.\nAssignment submissions are typically due on the week following their publication. You may submit via Canvas (preferred) or email (danilo.freire@emory.edu).\nI encourage you to complete assignments in Jupyter notebooks (.ipynb), Word documents, or PDFs. The assignment folders contain the questions in various formats, so you can use them as templates."
  },
  {
    "objectID": "assignments.html#assessment-overview",
    "href": "assignments.html#assessment-overview",
    "title": "Assignments",
    "section": "Assessment Overview",
    "text": "Assessment Overview\n\nProblem sets (10) — 50%. Short conceptual and practical tasks. Submit Jupyter notebooks (.ipynb), Word documents, or PDFs. Late submissions incur a 10% penalty per day unless authorised in advance. Collaboration for discussion is allowed but answers must be written independently; list collaborators on submission.\nIn-class quizzes (5) — 30%. Each quiz occupies a full lecture. Quizzes are open-book/open-notes and individual assessments. Discussion during quizzes is not permitted.\nFinal group project — 20%. Groups of 3–4 produce a report and a short demo video. The project involves conceptual elements and a harms assessment. More details will be provided in class."
  },
  {
    "objectID": "assignments.html#assignment-timeline",
    "href": "assignments.html#assignment-timeline",
    "title": "Assignments",
    "section": "Assignment Timeline",
    "text": "Assignment Timeline\n\n\n\n\n\n\n\n\n\nAssignment\nTopic\nDue Date\nRelated Lectures\n\n\n\n\nProblem Set 1\nOrientation & AI Basics\nWeek 3\nLectures 1-2\n\n\nProblem Set 2\nDataset Design & Learning Types\nWeek 5\nLectures 3-4\n\n\nProblem Set 3\nMetrics & Validation\nWeek 6\nLecture 5\n\n\nQuiz 1\nModules 0-1\nWeek 6\nLecture 6\n\n\nProblem Set 4\nLanguage & Perception\nWeek 8\nLectures 7-8\n\n\nProblem Set 5\nRetrieval & Generation\nWeek 10\nLectures 11-12\n\n\nQuiz 2\nModule 2\nWeek 10\nLecture 10\n\n\nProblem Set 6\nPipelines & Testing\nWeek 11\nLecture 13\n\n\nQuiz 3\nModule 3\nWeek 11\nLecture 14\n\n\nProblem Set 7\nBias & Fairness\nWeek 13\nLectures 15-16\n\n\nProblem Set 8\nCase Studies & Documentation\nWeek 14\nLecture 17\n\n\nQuiz 4\nModule 4\nWeek 14\nLecture 18\n\n\nProblem Set 9\nRegulation & Policy\nWeek 16\nLectures 19-20\n\n\nProblem Set 10\nApplications & Society\nWeek 17\nLectures 23-24\n\n\nQuiz 5\nModule 5\nWeek 16\nLecture 22\n\n\nFinal Project\nGroup Project\nEnd of Semester\nAll Modules"
  },
  {
    "objectID": "assignments.html#detailed-assignment-schedule",
    "href": "assignments.html#detailed-assignment-schedule",
    "title": "Assignments",
    "section": "Detailed Assignment Schedule",
    "text": "Detailed Assignment Schedule\n\nModule 0 — Orientation\nProblem Set 1 (Due: Week 3)\n\nTopics: Course introduction, AI overview, history of AI, transformer architecture\nCovers: Lectures 1-2\nFocus: Understanding AI concepts, historical context, and current applications\n\n\n\nModule 1 — How AI systems are designed\nProblem Set 2 (Due: Week 5)\n\nTopics: Dataset design, supervised vs unsupervised learning\nCovers: Lectures 3-4\nFocus: Data quality, learning paradigms, and basic ML concepts\n\nProblem Set 3 (Due: Week 6)\n\nTopics: Metrics, validation, overfitting\nCovers: Lecture 5\nFocus: Model evaluation, performance metrics, and validation techniques\n\nQuiz 1 (Week 6)\n\nCovers: Modules 0-1 (Lectures 1-5)\nFormat: In-class, open book, individual work\n\n\n\nModule 2 — Language and perception\nProblem Set 4 (Due: Week 8)\n\nTopics: Language processing, embeddings, computer vision\nCovers: Lectures 7-8\nFocus: Understanding how AI processes text, images, and audio\n\nQuiz 2 (Week 10)\n\nCovers: Module 2 (Lectures 7-9)\nFormat: In-class, open book, individual work\n\n\n\nModule 3 — Retrieval, generation and pipelines\nProblem Set 5 (Due: Week 10)\n\nTopics: RAG, vector search, hallucination\nCovers: Lectures 11-12\nFocus: Modern AI systems, retrieval augmentation, and reliability issues\n\nProblem Set 6 (Due: Week 11)\n\nTopics: Pipeline monitoring, testing, production systems\nCovers: Lecture 13\nFocus: Practical aspects of deploying and maintaining AI systems\n\nQuiz 3 (Week 11)\n\nCovers: Module 3 (Lectures 11-13)\nFormat: In-class, open book, individual work\n\n\n\nModule 4 — Data ethics and bias\nProblem Set 7 (Due: Week 13)\n\nTopics: Types of bias, fairness, documentation\nCovers: Lectures 15-16\nFocus: Ethical considerations, bias identification, and governance\n\nProblem Set 8 (Due: Week 14)\n\nTopics: Case studies, real-world applications\nCovers: Lecture 17\nFocus: Analysis of biased outcomes in various domains\n\nQuiz 4 (Week 14)\n\nCovers: Module 4 (Lectures 15-17)\nFormat: In-class, open book, individual work\n\n\n\nModule 5 — Policy, governance and social impact\nProblem Set 9 (Due: Week 16)\n\nTopics: AI regulation, privacy, data protection\nCovers: Lectures 19-20\nFocus: Legal frameworks, policy implications, and privacy concerns\n\nQuiz 5 (Week 16)\n\nCovers: Module 5 (Lectures 19-21)\nFormat: In-class, open book, individual work\n\n\n\nModule 6 — Applications, limits and projects\nProblem Set 10 (Due: Week 17)\n\nTopics: AI applications, misinformation, societal impact\nCovers: Lectures 23-24\nFocus: Real-world applications and their consequences"
  },
  {
    "objectID": "assignments.html#final-group-project",
    "href": "assignments.html#final-group-project",
    "title": "Assignments",
    "section": "Final Group Project",
    "text": "Final Group Project\nDue: End of Semester\nFormat: Groups of 3-4 students\nComponents: - Written report on an AI application - Short demo video - Harms assessment - Conceptual analysis\nKey Elements: - Design a small, realistic plan for an AI application - Include data needs, evaluation strategy, and harm-mitigation approach - Reflect on ethical, legal, and social questions - Demonstrate understanding of course concepts\nMore detailed instructions for the final project will be provided in class during the second half of the semester."
  },
  {
    "objectID": "assignments.html#submission-guidelines",
    "href": "assignments.html#submission-guidelines",
    "title": "Assignments",
    "section": "Submission Guidelines",
    "text": "Submission Guidelines\n\nFile Formats\n\nPreferred: Jupyter notebooks (.ipynb) with clear documentation\nAlternative: Word documents or PDFs with code screenshots\nFinal Project: Report (PDF) + demo video (MP4)\n\n\n\nCollaboration Policy\n\nDiscussion with classmates is encouraged for conceptual understanding\nAll written work must be your own\nList all collaborators on your submission\nDeclare any use of AI tools (ChatGPT, Claude, etc.)\n\n\n\nLate Policy\n\n10% penalty per day for late submissions\nExtensions available only with prior approval\nMedical emergencies require documentation\n\n\n\nAcademic Integrity\n\nAll AI use must be declared on submissions\nYou are responsible for the correctness of your work\nProper attribution required for all sources, including AI-generated content\nEmory Honour Code applies to all assessments"
  },
  {
    "objectID": "assignments.html#getting-help",
    "href": "assignments.html#getting-help",
    "title": "Assignments",
    "section": "Getting Help",
    "text": "Getting Help\nIf you need assistance with assignments: 1. Review lecture materials and readings 2. Consult with classmates (for discussion, not copying) 3. Attend office hours or schedule an appointment 4. Post questions in the course discussion forum 5. Email the instructor for specific concerns\nRemember that the purpose of these assignments is to help you learn and apply the concepts from the course. Don’t hesitate to ask for help when needed!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "",
    "text": "Welcome to DATASCI 185! This course offers a non-technical introduction to artificial intelligence and its effects on institutions, work and everyday life. The course is practical: students will learn how modern systems are designed and how to ask the right questions about data, reliability and harms. The course combines short demonstrations (no programming experience required), case studies, and project work. It is suitable for undergraduate students from any faculty who want a grounded understanding of what AI can and cannot do.\nWe will meet every Monday and Wednesday from 4:00pm to 4:50pm in the Psychology Building, Room 290. It is important to read the assigned readings before class, and make sure to check this website for updates and additional resources. If you have any questions, please feel free to contact me. I am here to help you succeed in this course and beyond."
  },
  {
    "objectID": "index.html#contact-information",
    "href": "index.html#contact-information",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "Contact Information",
    "text": "Contact Information\n\nName: Danilo Freire\nEmail: danilo.freire@emory.edu\nOffice Hours: By appointment at your convenience, please email me to schedule a meeting"
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, students will be able to:\n\nExplain the main ideas behind contemporary AI systems in plain language.\nIdentify common failure modes of AI systems and the data issues that cause them.\nRead and assess claims about AI in news articles, product pages and policy documents.\nDesign a small, realistic plan for an AI application, including data needs, evaluation, and a basic harm-mitigation strategy.\nReflect critically on ethical, legal and social questions raised by AI deployment."
  },
  {
    "objectID": "index.html#website-structure",
    "href": "index.html#website-structure",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "Website Structure",
    "text": "Website Structure\nThis website contains the course syllabus, lecture materials, and assignments for the course. The course repository at https://github.com/danilofreire/datasci185 is similarly structured. Feel free to explore the materials and use them as needed."
  },
  {
    "objectID": "index.html#getting-help",
    "href": "index.html#getting-help",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "Getting Help",
    "text": "Getting Help\nIf you encounter any issues with the course materials or have questions about the content, please:\n\nCheck the course syllabus and this README for relevant information\nReview the lecture materials in the repository\nConsult with your classmates or post in the course discussion forum\nAttend office hours or schedule an appointment with the instructor"
  },
  {
    "objectID": "index.html#contributing-to-the-repository",
    "href": "index.html#contributing-to-the-repository",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "Contributing to the Repository",
    "text": "Contributing to the Repository\nWhile this repository is primarily maintained by the course instructor, everyone is welcome to contribute. Please feel free to suggest improvements or report issues by opening a GitHub issue, submitting a pull request, creating a discussion post, or contacting the instructor directly."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "DATASCI 185 - Introduction to AI Applications",
    "section": "License",
    "text": "License\nThis repository is licensed under the MIT License. You are free to use, modify, and distribute the materials as needed, with appropriate attribution to the original source.\n\nWe look forward to an engaging and productive semester! Happy learning!"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DATASCI 185! This course offers a non-technical introduction to artificial intelligence and its effects on institutions, work and everyday life. The course is practical: students will learn how modern systems are designed and how to ask the right questions about data, reliability and harms. The course combines short demonstrations (no programming experience required), case studies, and project work. It is suitable for undergraduate students from any faculty who want a grounded understanding of what AI can and cannot do."
  },
  {
    "objectID": "syllabus.html#books",
    "href": "syllabus.html#books",
    "title": "Syllabus",
    "section": "Books",
    "text": "Books\n\nArtificial Intelligence: A Guide for Thinking Humans by Melanie Mitchell (2020). A clear, non-technical overview of AI concepts and history.\nThe Master Algorithm by Pedro Domingos (2015). A readable introduction to machine learning concepts and applications.\nThe Coming Wave: AI, Power, and Our Future by Mustafa Suleyman and Michael Bhaskar (2025). An award-winning book on the transformative potential of AI and its societal implications.\nThe Alignment Problem: Machine Learning and Human Values by Brian Christian (2020). An exploration of what can go wrong when AI systems are deployed in the real world.\nAI & I: An intellectual history of artificial intelligence. by Eugene Charniak (2024). A new book by a leading AI researcher, covering the history of the field from the 1950s to the present day.\nWeapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy by Cathy O’Neil (2016). A book on the dangers of unregulated mathematical models.\nAtlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence by Kate Crawford (2021). A critical look at the social and environmental impacts of AI technologies."
  },
  {
    "objectID": "syllabus.html#online-courses",
    "href": "syllabus.html#online-courses",
    "title": "Syllabus",
    "section": "Online Courses",
    "text": "Online Courses\n\nAI For Everyone by Andrew Ng (Coursera). A non-technical introduction to AI concepts and applications. Free to audit, with a paid certificate option.\nElements of AI by the University of Helsinki. A free, friendly introduction to AI and some of its methods.\nAI Essentials by Google (Coursera). This programme is designed for people who want to gain practical AI skills for the workplace with no experience required.\nGoogle Prompting Essentials by Google (Coursera). A short course on how to effectively use and design prompts for large language models.\nRadical Ideas in AI Ethics by Pragmatic AI Labs (edX). A course that discusses AI through the lens of human rights and digital autonomy."
  },
  {
    "objectID": "syllabus.html#other-resources",
    "href": "syllabus.html#other-resources",
    "title": "Syllabus",
    "section": "Other Resources",
    "text": "Other Resources\n\nIn Machines We Trust. A podcast series by MIT Technology Review about the promises and perils of AI. Very accessible and engaging.\nAI for the Rest of Us. 25-30 minute episodes focused on explaining AI concepts to non-technical listeners.\nThe Gradient. A publication that features accessible articles on AI research.\nAI Now Institute. Research institute focused on the social implications of AI.\nAI for Good Lab. A Microsoft research group that highlights how AI can change society for the better.\nThe AI Incident Database. A collection of real-world cases where AI systems have caused harm or failed.\nTeachable Machine. A web-based tool by Google that allows users to create simple machine learning models without coding.\nThe Algorithm. A newsletter by MIT Technology Review that covers the latest developments in AI."
  }
]